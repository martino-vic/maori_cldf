{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b750aca8-fb68-42cc-b482-0443aad8d324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mri</th>\n",
       "      <th>en</th>\n",
       "      <th>lenmri</th>\n",
       "      <th>lenen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PL , -b , Z , &gt; , v   ]</td>\n",
       "      <td>[PLACE NAMES ]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[Iti ]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Abisinia , Aearana , Aferika , Afrika , Aharo...</td>\n",
       "      <td>[Abysinnia , Ireland , Africa , Africa , , Asi...</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Arena , Arepia , Arikehanara , Aripa , Armeni...</td>\n",
       "      <td>[Aliens  Creek, Arabia , Alexandria, Alps, Arm...</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Britania , Britannia ]</td>\n",
       "      <td>[Britain , Britain ]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[Korowi , Kotepere , Koteriki , Kotiere , Koti...</td>\n",
       "      <td>[Leonida , Lisiniu ]</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[Ma, Maata , Maehe , Mahameta , Maharere , Mah...</td>\n",
       "      <td>[Clovis , Godfrey , Clotilde , Chrysostom , Cr...</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[Leonidas , Licinius ]</td>\n",
       "      <td>[Mary , Martha , Marsh , Mahomed , Marcellus ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[Makarita , Makehe , Makehe , Makentiu , Maker...</td>\n",
       "      <td>[Margaret , Maxentius , Marcus , Maxentius , M...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[Marino , Mata , Matene , Matene  Ruta , Maten...</td>\n",
       "      <td>[Marinus , Martha , Martin , Martin  Luther , ...</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mri  \\\n",
       "0                            [PL , -b , Z , > , v   ]   \n",
       "1                                                  []   \n",
       "2   [Abisinia , Aearana , Aferika , Afrika , Aharo...   \n",
       "3   [Arena , Arepia , Arikehanara , Aripa , Armeni...   \n",
       "4                             [Britania , Britannia ]   \n",
       "..                                                ...   \n",
       "65  [Korowi , Kotepere , Koteriki , Kotiere , Koti...   \n",
       "66  [Ma, Maata , Maehe , Mahameta , Maharere , Mah...   \n",
       "67                             [Leonidas , Licinius ]   \n",
       "68  [Makarita , Makehe , Makehe , Makentiu , Maker...   \n",
       "69  [Marino , Mata , Matene , Matene  Ruta , Maten...   \n",
       "\n",
       "                                                   en  lenmri  lenen  \n",
       "0                                      [PLACE NAMES ]       5      1  \n",
       "1                                              [Iti ]       1      1  \n",
       "2   [Abysinnia , Ireland , Africa , Africa , , Asi...      37     36  \n",
       "3   [Aliens  Creek, Arabia , Alexandria, Alps, Arm...      38     37  \n",
       "4                                [Britain , Britain ]       2      2  \n",
       "..                                                ...     ...    ...  \n",
       "65                               [Leonida , Lisiniu ]      10      2  \n",
       "66  [Clovis , Godfrey , Clotilde , Chrysostom , Cr...      27      7  \n",
       "67  [Mary , Martha , Marsh , Mahomed , Marcellus ,...       2     26  \n",
       "68  [Margaret , Maxentius , Marcus , Maxentius , M...      43     30  \n",
       "69  [Marinus , Martha , Martin , Martin  Luther , ...      43     29  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read pdf\n",
    "#clean data\n",
    "#write to excel\n",
    "#clean manually\n",
    "#convert to cldf\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_pdf_file_content(path_to_pdf):\n",
    "    resource_manager = PDFResourceManager(caching=True)\n",
    "    out_text = StringIO()\n",
    "    laParams = LAParams()\n",
    "    text_converter = TextConverter(resource_manager, out_text,laparams=laParams)\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_manager,text_converter)\n",
    "    for page in PDFPage.get_pages(fp,pagenos=set(),maxpages=0,password=\"\",caching=True,check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    text= out_text.getvalue()\n",
    "    \n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean1():\n",
    "    mri = get_pdf_file_content(\"duval_thesis_vol3-1-40.pdf\")\n",
    "    mri2=[]\n",
    "    for i in mri.split(\"\\n\\n\"):\n",
    "        if re.search('\\x0c[1-9]', i) or not re.search('[a-zA-Z]', i):\n",
    "            continue\n",
    "        else:\n",
    "            mri2.append(i)\n",
    "    return mri2\n",
    "\n",
    "def clean2():\n",
    "    i = iter(clean1())\n",
    "    counter=0\n",
    "    return pd.DataFrame(list(zip(i, i)), columns=[\"mri\",\"en\"])\n",
    "\n",
    "def clean3():\n",
    "    mri = clean2()\n",
    "    for col in [\"mri\", \"en\"]:\n",
    "        mri[col] = [re.sub(\"[1-9]\",\"\",i) for i in mri[col]]\n",
    "        mri[col] = [re.sub(\" *?\\[.*?\\]? *?\",\"\",i) for i in mri[col]]\n",
    "        mri[col] = [re.sub(\" *?\\(.*?\\) *\",\"\",i) for i in mri[col]]\n",
    "        mri[col] = [re.sub(\"[\\*\\?\\\"\\.'\\(\\)0\\;\\_\\]\\}·\\~]\",\"\",i) for i in mri[col]]\n",
    "    \n",
    "    mri[\"mri\"] = [i.split(\"\\n\") for i in mri[\"mri\"]]\n",
    "    mri[\"en\"] = [i.split(\"\\n\") for i in mri[\"en\"]]\n",
    "    \n",
    "    mri[\"en\"] = [None if i[0]==\"?\" else i for i in mri[\"en\"]]\n",
    "    mri[\"en\"] = [[j for j in i if j!=\" \"] for i in mri[\"en\"]]\n",
    "    mri = mri.dropna()\n",
    "    mri[\"lenmri\"] = list(map(len, mri[\"mri\"]))\n",
    "    mri[\"lenen\"] = list(map(len, mri[\"en\"]))\n",
    "    #print(\"Following rows have a different number of elements. Trim them manually.\")\n",
    "    #for k, (i,j) in enumerate(zip(mri[\"lenmri\"], mri[\"lenen\"])):\n",
    "     #   if i !=j:\n",
    "      #      print(k)\n",
    "            \n",
    "    mri.to_csv(\"duv95_coarse.csv\", encoding=\"utf_8_sig\", index=False)\n",
    "    #mri = mri.explode([\"mri\", \"en\"])\n",
    "       \n",
    "    return mri\n",
    "\n",
    "clean3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137cb574-e529-47d9-94fe-94ddd3fe9689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"a\", \"\", \"b\"]\n",
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342981a4-d888-4ecf-9b88-f9c9c7866cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.sub(\" *?\\(.*?\\) *\",\"\",\"Amsterdam (Holland)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68294e6a-de13-45fe-87ef-d60be00d8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(\"\".join(mri[\"mri\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456706d-7af0-470c-a0a9-67f629c31737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "mri = pd.read_csv(\"mri1.csv\")\n",
    "mri[\"en\"] = [None if i[0]==\"?\" else i for i in mri[\"en\"]]\n",
    "mri = mri.dropna()\n",
    "for col in [\"mri\", \"en\"]:\n",
    "    mri[col] = [re.sub(\"[1-9]\",\"\",i) for i in mri[col]]\n",
    "    mri[col] = [re.sub(\" *?\\[.*?\\]? *?\",\"\",i) for i in mri[col]]\n",
    "    mri[col] = [re.sub(\" *?\\(.*?\\) *\",\"\",i) for i in mri[col]]\n",
    "    mri[col] = [re.sub(\"[\\*\\?\\\"\\.'\\(\\)0\\;\\_\\]\\}·\\~]\",\"\",i) for i in mri[col]]\n",
    "mri.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27596cff-8fc8-466a-9a0b-6de68291b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mri = pd.read_excel(\"mripdf_pre.xlsx\")\n",
    "#mri[\"lenmri\"] = [len(i.split(\"\\n\")) for i in mri[\"mri\"]]\n",
    "#mri[\"lenen\"] = [len(i.split(\"\\n\")) for i in mri[\"en\"]]\n",
    "mri[\"mri\"] = [i.split(\"\\n\") for i in mri[\"mri\"]]\n",
    "mri[\"en\"] = [i.split(\"\\n\") for i in mri[\"en\"]]\n",
    "mri = mri.explode([\"mri\", \"en\"])\n",
    "#for k, (i,j) in enumerate(zip(mri[\"lenmri\"], mri[\"lenen\"])):\n",
    " #   if i !=j:\n",
    "  #      print(k)\n",
    "mri\n",
    "#for i,j in mri.iterrows():\n",
    " #   if i==15:\n",
    "   #     for k,l in zip(j[\"mri\"].split(\"\\n\"), j[\"en\"].split(\"\\n\")):\n",
    "  #          print(k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9562ee2f-b70b-46ac-a24d-9347c7d65ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri.to_csv(\"mri2.csv\", encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243d4f4-90dd-47d7-8d3c-2e077c75525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't really work\n",
    "import tabula\n",
    "\n",
    "# Read PDF into list of DataFrame\n",
    "dataframe = tabula.read_pdf(\"duval_thesis_vol3.pdf\", pages='all')\n",
    "\n",
    "# Read remote PDF into list of DataFrame\n",
    "#dataframe_2 = tabula.read_pdf(\"https://github.com/tabulapdf/tabula-java/raw/master/src/test/resources/technology/tabula/arabic.pdf\")\n",
    "\n",
    "# Convert PDF into CSV file\n",
    "tabula.convert_into(\"duval_thesis_vol3.pdf\", \"output.csv\", output_format=\"csv\", pages='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a45b38-fe75-44f9-94cf-14b114f8f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns pdf 2 txt but tricky to put that text into a df\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def get_pdf_file_content(path_to_pdf):\n",
    "    resource_manager = PDFResourceManager(caching=True)\n",
    "    out_text = StringIO()\n",
    "    laParams = LAParams()\n",
    "    text_converter = TextConverter(resource_manager, out_text,laparams=laParams)\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_manager,text_converter)\n",
    "    for page in PDFPage.get_pages(fp,pagenos=set(),maxpages=0,password=\"\",caching=True,check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    text= out_text.getvalue()\n",
    "    \n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "    \n",
    "    return text\n",
    "\n",
    "mri = get_pdf_file_content(\"duval_thesis_vol3-1-40.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce552c42-f92f-4554-973d-431a90b46535",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26effa5c-f348-4859-983b-a647225bef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(mri2)\n",
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50be866-7809-4f1a-90ad-9d62c347d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mri3 = pd.DataFrame(list(zip(i, i)), columns=[\"mri\",\"en\"])\n",
    "mri3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313463d-af61-4013-9d1f-185f628a8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri3.to_csv(\"duvalmri.csv\", encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb8cf2-83cb-4ef6-9c4b-ad920a6f42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter+=1\n",
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21150f-7241-4bc2-bfce-56d250ea4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mri2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde4311-777a-408d-b293-3a23ab2475aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search\n",
    "\n",
    "mri2=[]\n",
    "for i in mri.split(\"\\n\\n\"):\n",
    "    if search('\\x0c[1-9]', i) or not search('[a-zA-Z]', i):\n",
    "        continue\n",
    "    else:\n",
    "        mri2.append(i)\n",
    "mri2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706cc25-d73e-4e8e-bbc1-aa3c65699622",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b6697-866e-4d67-a15d-dfb25b84e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't work b/c \"poppler\" has a bug\n",
    "#https://www.geeksforgeeks.org/python-reading-contents-of-pdf-using-ocr-optical-character-recognition/\n",
    "# Import libraries\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Path of the pdf\n",
    "PDF_file = \"duval_thesis_vol3.pdf\"\n",
    "\n",
    "'''\n",
    "Part #1 : Converting PDF to images\n",
    "'''\n",
    "\n",
    "# Store all the pages of the PDF in a variable\n",
    "pages = convert_from_path(PDF_file, 189)#, poppler_path=r'C:\\Users\\Viktor\\OneDrive\\PhD cloud\\Vorgehensweisen\\loanpy11\\tests_phd\\test_adapter\\maori-en\\maori_en2\\poppler-0.68.0_x86\\bin')\n",
    "\n",
    "# Counter to store images of each page of PDF to image\n",
    "image_counter = 1\n",
    "\n",
    "# Iterate through all the pages stored above\n",
    "for page in pages:\n",
    "\n",
    "\t# Declaring filename for each page of PDF as JPG\n",
    "\t# For each page, filename will be:\n",
    "\t# PDF page 1 -> page_1.jpg\n",
    "\t# PDF page 2 -> page_2.jpg\n",
    "\t# PDF page 3 -> page_3.jpg\n",
    "\t# ....\n",
    "\t# PDF page n -> page_n.jpg\n",
    "\tfilename = \"page_\"+str(image_counter)+\".jpg\"\n",
    "\t\n",
    "\t# Save the image of the page in system\n",
    "\tpage.save(fr\"pdfimages\\{filename}\", 'JPEG')\n",
    "\n",
    "\t# Increment the counter to update filename\n",
    "\timage_counter = image_counter + 1\n",
    "\n",
    "'''\n",
    "Part #2 - Recognizing text from the images using OCR\n",
    "'''\n",
    "\n",
    "# Variable to get count of total number of pages\n",
    "filelimit = image_counter-1\n",
    "\n",
    "# Creating a text file to write the output\n",
    "outfile = \"out_text.txt\"\n",
    "\n",
    "# Open the file in append mode so that\n",
    "# All contents of all images are added to the same file\n",
    "f = open(outfile, \"a\")\n",
    "\n",
    "# Iterate from 1 to total number of pages\n",
    "for i in range(1, filelimit + 1):\n",
    "\n",
    "\t# Set filename to recognize text from\n",
    "\t# Again, these files will be:\n",
    "\t# page_1.jpg\n",
    "\t# page_2.jpg\n",
    "\t# ....\n",
    "\t# page_n.jpg\n",
    "\tfilename = \"page_\"+str(i)+\".jpg\"\n",
    "\t\t\n",
    "\t# Recognize the text as string in image using pytesserct\n",
    "\ttext = str(((pytesseract.image_to_string(Image.open(filename)))))\n",
    "\n",
    "\t# The recognized text is stored in variable text\n",
    "\t# Any string processing may be applied on text\n",
    "\t# Here, basic formatting has been done:\n",
    "\t# In many PDFs, at line ending, if a word can't\n",
    "\t# be written fully, a 'hyphen' is added.\n",
    "\t# The rest of the word is written in the next line\n",
    "\t# Eg: This is a sample text this word here GeeksF-\n",
    "\t# orGeeks is half on first line, remaining on next.\n",
    "\t# To remove this, we replace every '-\\n' to ''.\n",
    "\ttext = text.replace('-\\n', '')\t\n",
    "\n",
    "\t# Finally, write the processed text to the file.\n",
    "\tf.write(text)\n",
    "\n",
    "# Close the file after writing all the text.\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b9ebb-c304-4251-a0fb-e98d5800f946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
